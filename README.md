ğŸ›¡ï¸ Real-Time Fraud Detection & SIEM Pipeline

Ce projet est une solution complÃ¨te de dÃ©tection de menaces et de fraude en temps rÃ©el. Il utilise une architecture Big Data basÃ©e sur Apache Spark, Kafka et Elasticsearch (Stack ELK) pour ingÃ©rer, analyser et visualiser des attaques de cybersÃ©curitÃ© et des fraudes bancaires instantanÃ©ment.

ğŸ“‘ Table des MatiÃ¨res

Architecture du Projet

Description des Fichiers

PrÃ©requis

Installation et DÃ©marrage

Utilisation et Simulation

ğŸ— Architecture du Projet

Le pipeline suit le pattern "Kappa Architecture" pour le traitement de flux continu :

Ingestion (Sources) :

Logs systÃ¨mes (Syslog) via syslog-ng.

Transactions financiÃ¨res et logs Web simulÃ©s via des scripts PowerShell.

Message Broker (Tampon) :

Apache Kafka : Centralise tous les flux de donnÃ©es (topics syslogs et fraud_alerts).

Zookeeper : Gestionnaire du cluster Kafka.

Processing (Cerveau) :

Apache Spark Structured Streaming : Analyse les flux en temps rÃ©el. Il dÃ©tecte les modÃ¨les d'attaques (SSH Brute Force, SQL Injection, XSS) et enrichit les donnÃ©es (GeoIP).

Stockage & Indexation :

Elasticsearch : Base de donnÃ©es NoSQL optimisÃ©e pour la recherche et l'analytique.

Visualisation :

Kibana : Interface graphique pour le monitoring (Tableaux de bord, Cartes mondiales).

ğŸ“‚ Description des Fichiers

Voici le rÃ´le technique de chaque fichier prÃ©sent dans ce dÃ©pÃ´t :

1. Infrastructure & Configuration

docker-compose.yml : Le fichier maÃ®tre d'orchestration. Il dÃ©finit et lance tous les conteneurs (Spark Master/Worker, Kafka, Zookeeper, Elasticsearch, Kibana, Syslog-ng) et configure le rÃ©seau isolÃ© fraud-net.

syslog-ng.conf : Configuration du collecteur de logs. Il Ã©coute sur le port 514 (UDP) et redirige automatiquement tous les logs reÃ§us vers le topic Kafka syslogs.

start-detection.bat : Script d'automatisation pour Windows. Il :

Copie le script Python dans le conteneur Spark.

Configure les dÃ©pendances Java/Scala (Ivy).

Soumet le job (spark-submit) au cluster Spark avec les connecteurs Kafka et Elasticsearch nÃ©cessaires.

2. Logique de Traitement (Back-end)

spark_fraud_detection.py : Le cÅ“ur du systÃ¨me. Ce script PySpark :

Lit deux topics Kafka simultanÃ©ment.

Applique des Regex pour identifier les attaques textuelles (SSH, Web).

Parse les donnÃ©es JSON pour les fraudes bancaires (Carding).

Unifie les donnÃ©es dans un format standardisÃ©.

Ã‰crit les rÃ©sultats dans l'index Elasticsearch security_events en activant le pipeline GeoIP.

3. Simulation d'Attaques (Red Team Tools)

generate-attack.ps1 : Simule une attaque SSH Brute Force. Il gÃ©nÃ¨re des logs d'Ã©chec d'authentification et les injecte dans Kafka.

generate-web-attacks.ps1 : Simule des attaques Web (SQL Injection, XSS, Path Traversal, Scanners). Il utilise un encodage Base64 pour injecter des payloads complexes sans casser le shell.

generate-carding-attack.ps1 : Simule une fraude bancaire mondiale (Carding). Il gÃ©nÃ¨re des transactions JSON avec des montants et des coordonnÃ©es gÃ©ographiques dispersÃ©es pour tester la dÃ©tection de fraude financiÃ¨re.

4. Visualisation

dashboard.ndjson : Le fichier d'export de Kibana. Il contient la configuration complÃ¨te du tableau de bord, des visualisations (Pie charts, Histogrammes) et de la carte mondiale.

âš™ PrÃ©requis

Docker Desktop installÃ© et en cours d'exÃ©cution (avec au moins 4Go de RAM allouÃ©s).

Git pour cloner le projet.

PowerShell (Windows) pour lancer les scripts de simulation.

ğŸš€ Installation et DÃ©marrage

Suivez ces Ã©tapes pour dÃ©ployer le projet depuis zÃ©ro.

1. Cloner le dÃ©pÃ´t

git clone [https://github.com/BALLEGI/realtime-fraud-detection1](https://github.com/BALLEGI/realtime-fraud-detection1)
cd realtime-fraud-detection1


2. DÃ©marrer l'infrastructure

Lancez les conteneurs en arriÃ¨re-plan :

docker-compose up -d


Attendez environ 60 secondes que tous les services (notamment Kafka et Elastic) soient prÃªts.

3. Configuration Initiale (Une seule fois)

A. CrÃ©er les Topics Kafka
Ouvrez un terminal et exÃ©cutez :

docker exec kafka kafka-topics --create --topic syslogs --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
docker exec kafka kafka-topics --create --topic fraud_alerts --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1


B. Configurer Elasticsearch (Pipeline GeoIP & Template)
Ouvrez Kibana (http://localhost:5601), allez dans Dev Tools et exÃ©cutez ces deux commandes (bouton Play) :

Commande 1 : CrÃ©er le pipeline de gÃ©olocalisation

PUT /_ingest/pipeline/geoip-enrichment
{
  "description": "GeoIP enrichment for SIEM",
  "processors": [
    { "geoip": { "field": "source_ip", "target_field": "geoip", "ignore_failure": true } }
  ]
}


Commande 2 : DÃ©finir le Mapping parfait

PUT _index_template/security_template
{
  "index_patterns": ["security_events*"],
  "template": {
    "mappings": {
      "properties": {
        "@timestamp": { "type": "date" },
        "geoip": { "properties": { "location": { "type": "geo_point" } } },
        "source_ip": { "type": "ip" },
        "attack_type": { "type": "keyword" },
        "transaction": { "properties": { "amount": { "type": "double" } } }
      }
    }
  }
}


C. Importer le Dashboard

Allez dans Kibana > Stack Management > Saved Objects.

Cliquez sur Import et sÃ©lectionnez le fichier dashboard.ndjson inclus dans ce dÃ©pÃ´t.

4. Lancer le Moteur de DÃ©tection

Double-cliquez sur le fichier :
start-detection.bat
Une fenÃªtre console va s'ouvrir. Laissez-la ouverte, c'est votre moteur Spark qui tourne.

ğŸ® Utilisation et Simulation

Une fois le systÃ¨me lancÃ©, ouvrez 3 fenÃªtres PowerShell distinctes pour simuler une cyber-guerre en temps rÃ©el.

1. Attaque Web (SQLi / XSS)

.\generate-web-attacks.ps1


2. Fraude Bancaire (Carding)

.\generate-carding-attack.ps1


3. Attaque SystÃ¨me (SSH)

.\generate-attack.ps1
